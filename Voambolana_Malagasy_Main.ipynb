{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro"
      },
      "source": [
        "# üá≤üá¨ Voambolana Malagasy ‚Äî NLP Project\n",
        "\n",
        "Ce notebook centralise la collecte de donn√©es et la pr√©paration du mod√®le IA.\n",
        "\n",
        "### üìë √âtapes d'utilisation :\n",
        "1.  **Ex√©cutez la cellule de configuration** ci-dessous pour connecter votre Drive et r√©cup√©rer le code.\n",
        "2.  **Lancez les scrapers** (Phases 1-4) pour collecter les paroles.\n",
        "3.  **Nettoyez et Consolidez** (Phases 5-6) : Fusion Chansons + Bible + Wikip√©dia.\n",
        "4.  **Fondations NLP** (Phase 7-10) : Tokenizer, Normalisation et Embeddings.\n",
        "5.  **Applications** (Phase 12) : Testez le moteur de recherche et le correcteur."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup-header"
      },
      "source": [
        "## üõ†Ô∏è 1. Configuration (Drive + Git)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "setup-code"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# 1. Monter le Drive\n",
        "print(\"üîó Connexion √† Google Drive...\")\n",
        "try:\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    print(\"‚úÖ Drive mont√© avec succ√®s !\")\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Erreur lors du montage du Drive.\")\n",
        "\n",
        "# 2. Se placer dans le dossier du projet\n",
        "REPO_NAME = \"nlp_malagasy\"\n",
        "BASE_PATH = \"/content/drive/MyDrive/\" + REPO_NAME\n",
        "\n",
        "if not os.path.exists(BASE_PATH):\n",
        "    %cd /content/drive/MyDrive\n",
        "    !git clone https://github.com/franck504/nlp_malagasy.git\n",
        "\n",
        "%cd $BASE_PATH\n",
        "!git pull origin main\n",
        "\n",
        "print(f\"\\nüìç Position actuelle : {os.getcwd()}\")\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scraping-title"
      },
      "source": [
        "# üèóÔ∏è PARTIE 1 : COLLECTE DES DONN√âES (Scraping)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phase1-4-code"
      },
      "outputs": [],
      "source": [
        "!pip install requests beautifulsoup4\n",
        "%cd $BASE_PATH/tononkira_rehetra\n",
        "\n",
        "print(\"--- SCRAPING & MERGE ---\")\n",
        "!python 01_discover_artists.py --delay 1.0\n",
        "!python 02_scrape_lyrics.py --delay 0.5 --artist-workers 4 --song-workers 10\n",
        "!python 04_merge_corpus.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cleaning-title"
      },
      "source": [
        "# üßπ PARTIE 2 : NETTOYAGE ET CONSOLIDATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phase5-6-code"
      },
      "outputs": [],
      "source": [
        "%cd $BASE_PATH/tononkira_rehetra\n",
        "print(\"--- CLEANING & WIKI ---\")\n",
        "!python 05_clean_corpus.py --input malagasy_lyrics_corpus.txt --output malagasy_lyrics_cleaned.txt\n",
        "!python 10_download_wikipedia.py\n",
        "!python 11_extract_wiki.py\n",
        "\n",
        "print(\"\\n--- CONSOLIDATION FINALE (Lyrics + Bible + Wiki) ---\")\n",
        "!python 06_consolidate_corpus.py --lyrics malagasy_lyrics_cleaned.txt --bible ../from_bible_json --wiki ../malagasy_wikipedia_raw.txt --output malagasy_corpus_v2_final.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlp-title"
      },
      "source": [
        "# üß† PARTIE 3 : FONDATIONS NLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phase7-10-code"
      },
      "outputs": [],
      "source": [
        "!pip install tokenizers gensim\n",
        "%cd $BASE_PATH/tononkira_rehetra\n",
        "\n",
        "print(\"--- TOKENIZATION & EMBEDDINGS ---\")\n",
        "!python 07_train_tokenizer.py --corpus malagasy_corpus_v2_final.txt --output tokenizer_mg\n",
        "!python 09_normalize_corpus.py --input malagasy_corpus_v2_final.txt --output malagasy_corpus_normalized.txt\n",
        "!python 08_train_embeddings.py --corpus malagasy_corpus_normalized.txt --output embeddings_mg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "app-title"
      },
      "source": [
        "# üöÄ PARTIE 4 : APPLICATIONS (D√âMO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "app-index-header"
      },
      "source": [
        "### üèóÔ∏è 1. Indexation S√©mantique\n",
        "\n",
        "> [!IMPORTANT]\n",
        "> **BOUST TURBO (Recommand√© sur Drive)** : Ex√©cutez le script 13 d'abord pour regrouper les 14 000 fichiers en un seul. Cela acc√©l√®re l'indexation de fa√ßon spectaculaire."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "app-bundle-code"
      },
      "outputs": [],
      "source": [
        "%cd $BASE_PATH/tononkira_rehetra\n",
        "print(\"üöÄ Regroupement des chansons (Turbo Bundle)...\")\n",
        "!python 13_bundle_songs.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "app-index-code"
      },
      "outputs": [],
      "source": [
        "%cd $BASE_PATH/tononkira_rehetra\n",
        "print(\"üèóÔ∏è Indexation s√©mantique (via le bundle)...\")\n",
        "!python 12_test_app.py --index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "app-demo-header"
      },
      "source": [
        "### üîç 2. Tableau de Bord Interactif\n",
        "Modifiez les param√®tres ci-dessous pour tester l'intelligence du mod√®le."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "app-demo-code"
      },
      "outputs": [],
      "source": [
        "%cd $BASE_PATH/tononkira_rehetra\n",
        "\n",
        "RECHERCHE_SENS = \"Fitiavana sy fahatokiana\"  # @param {type:\"string\"}\n",
        "CORRECTION_MOT = \"fityavana\"               # @param {type:\"string\"}\n",
        "EXPLORER_CONCEPT = \"Antananarivo\"          # @param {type:\"string\"}\n",
        "STYLE_A_DETECTER = \"Andriamanitra √¥, tahio ny tany\" # @param {type:\"string\"}\n",
        "\n",
        "print(f\"--- üîç RECHERCHE S√âMANTIQUE : {RECHERCHE_SENS} ---\")\n",
        "!python 12_test_app.py --query \"{RECHERCHE_SENS}\"\n",
        "\n",
        "print(f\"\\n--- üìù CORRECTION : {CORRECTION_MOT} ---\")\n",
        "!python 12_test_app.py --spell \"{CORRECTION_MOT}\"\n",
        "\n",
        "print(f\"\\n--- üß† ANALYSE DE CONCEPT : {EXPLORER_CONCEPT} ---\")\n",
        "!python 12_test_app.py --explore \"{EXPLORER_CONCEPT}\"\n",
        "\n",
        "print(f\"\\n--- üé≠ D√âTECTION DE STYLE ---\")\n",
        "!python 12_test_app.py --style \"{STYLE_A_DETECTER}\"\n",
        "\n",
        "print(f\"\\n--- ‚öñÔ∏è ANALOGIE ---\")\n",
        "!python 12_test_app.py --analogy lehilahy mpanjaka vehivavy"
      ]
    }
  ]
}